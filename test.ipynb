{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import utils.gol as gol\n",
    "import numpy as np\n",
    "import torch\n",
    "gol._init()\n",
    "gol.set_value('device', 'cuda:1')\n",
    "from environments.mujoco.ant_goal_cluster import AntGoalClusterEnv\n",
    "from environments.mujoco.ant_dir_cluster import AntDirClusterEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04327524  0.69078721 -0.57207887  1.29217531]\n",
      " [ 0.26322138 -1.87145274 -1.48656541 -2.00062924]\n",
      " [ 0.28909475  1.46297013 -0.10675882  0.97841841]\n",
      " [ 0.47832591 -0.77301679 -1.66078182  0.97493419]]\n",
      "the first method: (array([[ 0.13204075,  4.10995605,  0.36984113,  1.42719716],\n",
      "       [ 0.3411623 , -4.72980429,  0.40823923, -0.93864325],\n",
      "       [ 0.25193344,  2.48602508,  0.01971243,  0.3086486 ],\n",
      "       [ 0.27486352, -0.86617684,  0.20220721,  0.2027975 ]]), 49.865269079484165)\n",
      "[[ 0.04327524  0.69078721 -0.57207887  1.29217531]\n",
      " [ 0.26322138 -1.87145274 -1.48656541 -2.00062924]\n",
      " [ 0.28909475  1.46297013 -0.10675882  0.97841841]\n",
      " [ 0.47832591 -0.77301679 -1.66078182  0.97493419]]\n",
      "the second method: tensor([[ 0.1320,  4.1100,  0.3698,  1.4272],\n",
      "        [ 0.3412, -4.7298,  0.4082, -0.9386],\n",
      "        [ 0.2519,  2.4860,  0.0197,  0.3086],\n",
      "        [ 0.2749, -0.8662,  0.2022,  0.2028]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# the original optimal transport problem solver\n",
    "\n",
    "def compute_optimal_transport(M, r, c, lam, epsilon=1e-5):     \n",
    "    n, m = M.shape     \n",
    "    # P = np.exp(- lam * M)\n",
    "    # Avoiding poor math condition     \n",
    "    P = M\n",
    "    P /= P.sum()     \n",
    "    u = np.zeros(n)\n",
    "    # Normalize this matrix so that P.sum(1) == r, P.sum(0) == c     \n",
    "    for i in range(10):         \n",
    "        # Shape (n, )         \n",
    "        u = P.sum(1)\n",
    "        P *= (r / u).reshape((-1, 1))         \n",
    "        P *= (c / P.sum(0)).reshape((1, -1))     \n",
    "    \n",
    "    return P, np.sum(P * M)\n",
    "\n",
    "\n",
    "M = np.random.randn(4, 4)\n",
    "print(M)\n",
    "print(\"the first method:\", compute_optimal_transport(copy.deepcopy(M), np.ones(4), np.ones(4), lam=0.2, epsilon=0.01))\n",
    "\n",
    "# the sinkhorn-knoll in the current code\n",
    "@torch.no_grad()\n",
    "def sinkhorn(Q):\n",
    "    # Q = torch.exp(scores / self.args.epsilon).t() # Q is K-by-B for consistency with notations from our paper\n",
    "    B = Q.shape[1]  # number of samples to assign\n",
    "    K = Q.shape[0]  # how many prototypes\n",
    "\n",
    "    # make the matrix sums to 1\n",
    "    sum_Q = torch.sum(Q)\n",
    "    # dist.all_reduce(sum_Q)\n",
    "    Q /= sum_Q\n",
    "    Q *= B # the colomns must sum to 1 so that Q is an assignment\n",
    "    \n",
    "    for it in range(10):\n",
    "        # normalize each row: total weight per prototype must be 1/K\n",
    "        sum_of_rows = torch.sum(Q, dim=1, keepdim=True)\n",
    "        # dist.all_reduce(sum_of_rows)\n",
    "        Q /= sum_of_rows\n",
    "        # Q /= K\n",
    "\n",
    "        # normalize each column: total weight per sample must be 1/B\n",
    "        Q /= torch.sum(Q, dim=0, keepdim=True)\n",
    "        # Q /= B\n",
    "\n",
    "    \n",
    "    return Q\n",
    "\n",
    "print(M)\n",
    "print(\"the second method:\", sinkhorn(torch.from_numpy(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.810956853079488\n",
      "-1.8109568530794875\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(4, 4)\n",
    "B = np.random.randn(4, 4)\n",
    "print(np.sum(A * B))\n",
    "print(np.dot(A.T, B).trace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66626409 -3.28637241 -0.11529508  0.96383359]\n",
      " [-1.33434205  2.06294486 -1.54455869 -0.83923558]\n",
      " [-1.00172206  2.20889372 -0.59780513  0.14056552]\n",
      " [ 0.75693611 -1.07924075  1.01225128  0.29206287]\n",
      " [ 0.4814222   0.28424167 -1.57707098 -0.46884366]\n",
      " [ 1.25558147 -1.01464578  1.55881364  0.50988612]\n",
      " [-0.12671393  0.20937435  1.52011385  0.48144126]\n",
      " [-1.43945091 -1.2030839  -0.89878742 -1.65948718]\n",
      " [-0.88681909  2.20409042  1.28839136  1.73192686]\n",
      " [-0.12319705  0.64734347 -0.15474894  0.39944466]]\n",
      "the second method: tensor([[2.7652e-07, 2.2670e-21, 1.9696e-06, 1.0000e+00],\n",
      "        [8.9755e-13, 1.0000e+00, 3.1617e-15, 3.8205e-11],\n",
      "        [5.8045e-12, 1.0000e+00, 9.5011e-12, 1.5977e-07],\n",
      "        [7.2819e-01, 1.5155e-11, 2.6971e-01, 2.0998e-03],\n",
      "        [9.9970e-01, 2.7305e-04, 3.3096e-11, 2.2478e-05],\n",
      "        [6.2569e-01, 1.6967e-13, 3.7420e-01, 1.0881e-04],\n",
      "        [2.4432e-06, 1.3813e-07, 9.9968e-01, 3.2209e-04],\n",
      "        [1.3370e-01, 2.7885e-03, 8.5905e-01, 4.4603e-03],\n",
      "        [8.1149e-12, 4.2232e-01, 6.5453e-04, 5.7702e-01],\n",
      "        [1.6277e-02, 7.0909e-02, 3.4227e-04, 9.1247e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "M = np.random.randn(10, 4)\n",
    "print(M)\n",
    "@torch.no_grad()\n",
    "def sinkhorn(scores):\n",
    "    Q = torch.exp(scores / 0.1).t() # Q is K-by-B for consistency with notations from our paper\n",
    "    B = Q.shape[1]  # number of samples to assign\n",
    "    K = Q.shape[0]  # how many prototypes\n",
    "\n",
    "    # make the matrix sums to 1\n",
    "    sum_Q = torch.sum(Q)\n",
    "    # dist.all_reduce(sum_Q)\n",
    "    Q /= sum_Q\n",
    "    Q *= B # the colomns must sum to 1 so that Q is an assignment\n",
    "    \n",
    "    for it in range(200):\n",
    "        # normalize each row: total weight per prototype must be 1/K\n",
    "        sum_of_rows = torch.sum(Q, dim=1, keepdim=True)\n",
    "        # dist.all_reduce(sum_of_rows)\n",
    "        Q /= sum_of_rows\n",
    "        # Q /= K\n",
    "\n",
    "        # normalize each column: total weight per sample must be 1/B\n",
    "        Q /= torch.sum(Q, dim=0, keepdim=True)\n",
    "        # Q /= B\n",
    "\n",
    "    \n",
    "    return Q.t()\n",
    "\n",
    "# print(M)\n",
    "test_results = sinkhorn(torch.from_numpy(M))\n",
    "print(\"the second method:\", sinkhorn(torch.from_numpy(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varibad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8043e040fbc5882c7e3ca0fd63772ab135c605bb10d5b22dffad8c484ec61675"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
